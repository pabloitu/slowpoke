{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sse_plusTranch.to_csv('cat_sse_plusTranch.csv', index = False)\n",
    "\n",
    "cat_sse_plusTranch.replace('-', np.nan, inplace=True)\n",
    "\n",
    "df1 = cat_sse_plusTranch[['depth', 'mag', 'strike', 'dip', 'length', 'width',\n",
    "       'slip', 'duration']]\n",
    "\n",
    "# A (miss 7%): age\n",
    "# alphaS (miss 15%): shallow slab dip measured between 0 and 125 km depth\n",
    "# ZT (miss 0): trench depth\n",
    "# Tchannel (miss 50%): subduction channel sediment thickness (potentially subject to large variations) \n",
    "# Phi: thermal parameter, product of A with the vertical component of trench-normal subduction velocity \n",
    "# M56_vs: subduction velocity, accounting for upper plate deformation\n",
    "# Vup1 (miss 0): upper plate velocity\n",
    "# Vsub1 (miss 0): subducting plate velocity\n",
    "# Vt (miss 0): trench velocity\n",
    "# M56_vc: convergence velocity \n",
    "col_to_corr = ['A', 'alphaS', 'ZT', 'Tchannel', 'Phi', 'M56_vs', 'M56_vc' ,'Vup1', 'Vsub1', 'Vt1']\n",
    "\n",
    "df2 = cat_sse_plusTranch[col_to_corr]\n",
    "# If df1 and df2 have different columns and you want *all pairwise* correlations:\n",
    "results_corr = pd.DataFrame(index=['depth', 'mag', 'strike', 'dip', 'length', 'width',\n",
    "       'slip', 'duration'], columns=col_to_corr)\n",
    "results_pv = pd.DataFrame(index=['depth', 'mag', 'strike', 'dip', 'length', 'width',\n",
    "       'slip', 'duration'], columns=col_to_corr)\n",
    "\n",
    "for col1 in df1.columns:\n",
    "    for col2 in df2.columns:\n",
    "        s1 = df1[col1]\n",
    "        s2 = df2[col2]\n",
    "        mask = ~np.isnan(s1) & ~np.isnan(s2)\n",
    "        s1 = s1[mask]\n",
    "        s2 = s2[mask]\n",
    "        # Compute correlation with dropped NaNs\n",
    "        corr, p_value = pearsonr(s1, s2)\n",
    "        results_corr.loc[col1, col2] = corr\n",
    "        results_pv.loc[col1, col2] = p_value\n",
    "\n",
    "# Flatten the DataFrame\n",
    "filtered_corr = results_corr.stack().astype(float)\n",
    "\n",
    "filtered_corr = filtered_corr[(filtered_corr > 0.2) | (filtered_corr < -0.2)]\n",
    "#filtered_pv = filtered_pv[(filtered_corr > 0.2) | (filtered_corr < -0.2)]\n",
    "\n",
    "# Optional: sort values\n",
    "filtered_corr = filtered_corr.sort_values(ascending=False)\n",
    "\n",
    "# Show result\n",
    "print(filtered_corr)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
